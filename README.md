requisitos: Windows / Linux / Docker
precisamos instalar o nvidia-smi (GPUutil utiliza ele)
precisamos instalar os binarios o ffmpeg e INCLUIR ELE no .ENV
poetry >= 2.*



# ğŸ§â†’ğŸ“ MLET Playground: Transcrever, Fichar e Avaliar (Streamlit + Transformers)

Este projeto implementa um **playground em Streamlit** que:
- Recebe link do YouTube **ou** upload de vÃ­deo/Ã¡udio,
- **Extrai** e **transcreve** com WhisperX,
- **Gera Fichamento Markdown** e **Quiz** com **Hugging Face Transformers**,
- Oferece **download** dos artefatos.


---

## ğŸ§° Requisitos

- **Python 3.10+**
- **FFmpeg** (instalado localmente *ou* use **Docker**)
- **Poetry** (gerenciador de dependÃªncias)
- (Opcional) **GPU CUDA** para acelerar WhisperX/Transformers
  Execute no terminal para verificar a versÃ£o do Cuda em sua mÃ¡quina
  ```bash
  nvidia-smi
  ```
  Ajuste o pyproject.toml de acordo com o que Ã© indicado em "https://pytorch.org/get-started/locally/"

- (Opcional) Token HF (`HUGGINGFACE_TOKEN`) para alguns modelos

---

## ğŸš€ Setup (local)

```bash
# 1) Clone
git clone <SEU_REPO>.git
cd mlet-fase4-playground

# 2) Ambiente
pip install -U pip
pip install poetry==2.1.1
poetry install

# 3) VerificaÃ§Ã£o de Hardware
poetry run python -m src.core.device

# 4) ConfiguraÃ§Ã£o
cp .env.example .env
# edite .env se necessÃ¡rio (modelo HF, device, etc.)

# 5) Executar
poetry run streamlit run src/app/streamlit_app.py
```

Acesse: [http://localhost:8501](http://localhost:8501/)

---

## ğŸ³ Setup com Docker

```bash
# build
docker compose build

# run
docker compose up
```

Acesse: [http://localhost:8501](http://localhost:8501/)

---

## ğŸ§ª Como usar

1. **Escolha a fonte** (URL do YouTube ou Upload).
2. Clique em **Baixar & Processar** (se URL) ou envie o arquivo.
3. Clique em **Transcrever & Gerar**.
4. Baixe o **`Fichamento.md`** e o **`Quiz.json`**.

> _Dica:_ Ã¡udios longos podem demorar. Para MVP, use conteÃºdos de 5â€“15 min.

---

## ğŸ¤– Ajuste Fino (opcional)

Prepare um dataset (CSV/JSON/JSONL) com colunas:
- `text` â†’ entrada (trechos da transcriÃ§Ã£o)
- `target` â†’ saÃ­da (fichamento/quiz no formato escolhido)

Execute:

```bash
poetry run python -m src.training.finetune data/datasets/train.jsonl models/finetuned
```

Depois, aponte `HF_MODEL_NAME=models/finetuned` no `.env`.

---

## ğŸ§ª AvaliaÃ§Ã£o RÃ¡pida

Exemplo (heurÃ­stica simples):

```bash
poetry run python scripts/sample_eval.py data/outputs/quiz_*.json
```

(Edite `sample_eval.py` para mÃ©tricas de cobertura/consistÃªncia.)

---

## ğŸ“¦ Estrutura

```
src/
  app/streamlit_app.py      # UI do Playground
  nlp/transcribe.py         # WhisperX
  nlp/generate.py           # Transformers (fichamento/quiz)
  training/finetune.py      # ajuste fino opcional
  ...
```

---

## ğŸ” ObservaÃ§Ãµes

- **DiarizaÃ§Ã£o Ã© opcional**; requer modelos pyannote (podem exigir token HF).
- Para **GPU**, ajuste `torch`/`accelerate` conforme sua placa.

---

## ğŸŒ Deploy no Streamlit Cloud

1. Suba o repositÃ³rio no GitHub.
2. Crie um app no Streamlit Community Cloud apontando para `src/app/streamlit_app.py`.
3. Defina **Secrets** com o conteÃºdo do seu `.env` (sem aspas).
4. (Opcional) Ajuste variÃ¡veis de ambiente para cache de modelos.


---

## ğŸ“„ Entrega (conforme prova)

- **RepositÃ³rio GitHub** (este)
- **Link do Deploy Streamlit**
- **VÃ­deo (â‰¥ 5 min)** explicando tema, modelo, dados (se houver), ajuste fino, avaliaÃ§Ã£o, demonstraÃ§Ã£o.